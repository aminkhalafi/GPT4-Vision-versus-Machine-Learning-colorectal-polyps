import os
import cv2
import numpy as np
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications.resnet50 import preprocess_input
from sklearn.utils import shuffle
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, roc_auc_score, roc_curve, auc, confusion_matrix)
import time
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.calibration import calibration_curve

# Function to preprocess image for ResNet50
def preprocess_image_resnet(image_path):
    img = load_img(image_path, target_size=(300, 300))
    img_array = img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)
    return img_array

# Load ResNet50 model
base_model = ResNet50(weights='resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(300, 300, 3))

# Freeze the layers of the base model
base_model.trainable = False

# Build multi-class classification model on top of the pretrained ResNet50
num_classes = 6  # Change this based on the number of your classes
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(num_classes, activation='softmax')  # Multi-class classification output
])

# Compile the model
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Paths to data (replace these placeholders with your actual paths)
train_annotation_file = 'D:\\research\\colonoscopy\\ai_colon\\polyp_images\\keys\\all_keys_labmod_aug.csv'
train_image_folder = 'D:\\research\\colonoscopy\\ai_colon\\polyp_images\\all'
test_annotation_file = 'D:\\research\\colonoscopy\\ai_colon\\test_set\\keys_test\\all_test_labmod.csv'
test_image_folder = 'D:\\research\\colonoscopy\\ai_colon\\test_set\\all_test'

# Load training set
train_annotations = pd.read_csv(train_annotation_file)
train_images = []
train_labels = []

for index, row in train_annotations.iterrows():
    image_name = row['image_name']
    image_path = os.path.join(train_image_folder, image_name)
    processed_image = preprocess_image_resnet(image_path)

    if processed_image is not None:
        train_images.append(processed_image)
        label = row['polyp_type']  # Assuming 'label' is the column containing class information
        train_labels.append(label)
    else:
        print(f"Error loading image: {image_name}")

# Convert lists to numpy arrays
X_train = np.vstack(train_images)
y_train = np.array(train_labels)

# Ensure class labels start from 0
y_train = y_train - 1

# One-hot encode the labels for multi-class classification
y_train = np.eye(num_classes)[y_train.astype(int)]


# Shuffle data to randomize order
X_train, y_train = shuffle(X_train, y_train, random_state=42)

start_time = time.time()
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)
end_time = time.time()

# Load testing set
test_annotations = pd.read_csv(test_annotation_file)
test_images = []
test_labels = []

for index, row in test_annotations.iterrows():
    image_name = row['image_name']
    image_path = os.path.join(test_image_folder, image_name)
    processed_image = preprocess_image_resnet(image_path)

    if processed_image is not None:
        test_images.append(processed_image)
        label = row['polyp_type']  # Assuming 'label' is the column containing class information
        test_labels.append(label)
    else:
        print(f"Error loading image: {image_name}")

# Convert lists to numpy arrays
X_test = np.vstack(test_images)
y_test = np.array(test_labels)

# Ensure class labels start from 0
y_test = y_test - 1

# One-hot encode the labels for multi-class classification
y_test = np.eye(num_classes)[y_test.astype(int)]


# Shuffle data to randomize order
X_test, y_test = shuffle(X_test, y_test, random_state=42)

inference_start_time = time.time()
y_pred = model.predict(X_test)
inference_end_time = time.time()
y_pred_class = np.argmax(y_pred, axis=1)

# Evaluation metrics
accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_class)
precision = precision_score(np.argmax(y_test, axis=1), y_pred_class, average='weighted')
recall = recall_score(np.argmax(y_test, axis=1), y_pred_class, average='weighted')
f1 = f1_score(np.argmax(y_test, axis=1), y_pred_class, average='weighted')
class_report = classification_report(np.argmax(y_test, axis=1), y_pred_class)
training_time = end_time - start_time
inference_time = inference_end_time - inference_start_time
conf_matrix = confusion_matrix(y_test, y_pred_class)

print("Training Time:", training_time, "seconds")
print("Inference Time:", inference_time, "seconds")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-Score:", f1)
print("Classification Report:\n", class_report)
print("confusion matrix:", conf_matrix)
